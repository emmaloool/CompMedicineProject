{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"aa_idx = {'A':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'I':8, 'K':9, \n            'L':10, 'M':11, 'N':12, 'P':13, 'Q':14, 'R':15, 'S':16, 'T':17, \n            'V':18, 'W':19, 'Y':20, '-':21}\n\ndef blosum(seq, k):\n  print(\"BLOSUM-ing: \", seq)\n  s = list(seq)\n  if (len(s) < k):\n    s = s + (['*'] * (k - len(s)))\n  else:\n    s = s[0:k]\n  vec = pd.DataFrame([blosum_mat[i] for i in s]).iloc[:, (list(np.arange(20)) + [23])].values.flatten()\n  return vec\n\ndef onehot(seq, k=15):\n  print(seq)\n  s = list(seq)\n  if (len(s) < k):\n    s = s + (['-'] * (k - len(s)))\n  else:\n    s = s[0:k]\n  \n  vec = []\n  for let in range(k):\n    char = s[let]\n    row = np.zeros((21))\n    if (char not in aa_idx):\n      char = '-'\n    row[aa_idx[char]-1] = 1\n    vec.append(row)\n    if (char == '-'):\n      row = np.ones((21)) * (-400000)\n  vec = np.array(vec).flatten()\n  return vec\n\ndef softhot(seq, k=15):\n  s = list(seq)\n  if (len(s) < k):\n    s = s + (['-'] * (k - len(s)))\n  else:\n    s = s[0:k]\n  \n  vec = []\n  for let in range(k):\n    char = s[let]\n    row = np.ones((21)) * ((0.1)/(20)) \n    if (char not in aa_idx):\n      char = '-'\n    row[aa_idx[char]-1] = 0.9\n    vec.append(row)\n    if (char == '-'):\n      row = np.ones((21)) * (-400000)\n  vec = np.array(vec).flatten()\n  return vec\n\n# met refers to function\ndef encode_seq(method, peptide_seqs):\n  methods_dict = {'ONEHOT':onehot, 'BLOSUM':blosum, 'SOFTHOT':softhot}\n  met = methods_dict[method]\n  mapped = peptide_seqs.apply(lambda x: met(x))\n  return mapped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def AAC(peptide_seq):\n    peptide_ls = list(peptide_seq)\n    peptide_ls = [x for x in peptide_ls if x in aa_idx]\n    peptide_mapped = np.array(list(map(lambda x: aa_idx[x] - 1, peptide_ls)))\n    counts = np.bincount(peptide_mapped, minlength=20)\n    counts = counts / (len(peptide_ls))\n    \n    return counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Map AAC encoding onto each pseudo-seq, HLA seq\ndef pseudo_to_AAC(df):\n    return df['HLA'].apply(lambda x: AAC(x))\n\ndef to_np(vals):\n    X = []\n    for x in vals:\n        X.append(x)\n    X = np.array(X)\n    return X\n\ndef process_input_df(df):\n    X_hla = df['HLA'].apply(lambda x: AAC(x))\n    # epitope sequences --> each string row maps to its encoding to make a Series of numpy arrays\n    X_seqs = df['Sequence'].apply(lambda x: AAC(x))\n    # hla pseudosequences --> same business\n    X_hla = to_np(X_hla.values)\n    X_seqs = to_np(X_seqs.values)\n    # (num samples) by (40 where first 20 is encoding of epitope and next 20 pseudoseq encoding)\n    X_full = np.concatenate((X_seqs, X_hla), axis=1)\n    y = df['Y_val'].values\n    \n    return X_full, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_binding = pd.DataFrame(pd.read_csv(\"../input/binding-train-pseudo/binding_train_pseudo.csv\", index_col=0))\ndf_train_binding = df_train_binding[df_train_binding['Pep_Length'] <= 9]\nX, y = process_input_df(df_train_binding)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Network architecture:\n# input layer takes 1x49x21 tensor\n# hidden layer has 20 fully connected units\n# output layer uses relu activation, outputs either\n#     - binding strength between 0 and 1 inclusive\n#     - 0 (no binding) or 1 (binding)\n#     - 0 (no immunogen) or 1 (immunogen)\n# \ndef wider_model(hidden_units=20, input_dim=40):\n    # create model\n    model = Sequential()\n    model.add(Dense(hidden_units, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    # Compile model\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    return model\n\ndef model_30():\n    model = wider_model(30)\n    return model\n\ndef model_40():\n    model = wider_model(40)\n    return model\n\ndef model_50():\n    model = wider_model(50)\n    return model\n\ndef model_60():\n    model = wider_model(60)\n    return model\n\ndef model_70():\n    model = wider_model(70)\n    return model\n\ndef model_80():\n    model = wider_model(80)\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Network architecture:\n# input layer takes 1x49x21 tensor\n# hidden layer has 20 fully connected units\n# output layer uses relu activation, outputs either\n#     - binding strength between 0 and 1 inclusive\n#     - 0 (no binding) or 1 (binding)\n#     - 0 (no immunogen) or 1 (immunogen)\n# \ndef wider_classif_model(hidden_units=20, input_dim=40):\n    # create model\n    model = Sequential()\n    model.add(Dense(hidden_units, input_dim=input_dim, kernel_initializer='normal', activation='sigmoid'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam')\n    return model\n\ndef model_40():\n    model = wider_classif_model(40)\n    return model\n\ndef model_60():\n    model = wider_classif_model(60)\n    return model\n\ndef model_80():\n    model = wider_classif_model(80)\n    return model\n\nx = wider_classif_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate model with standardized dataset\n\ndef evaluator(func, i, X, y, scoring='neg_mean_squared_error'):\n    print(\"Got model\")\n    estimators = []\n    estimators.append(('standardize', StandardScaler()))\n    estimators.append(('mlp', KerasRegressor(build_fn=func, epochs=5, batch_size=5, verbose=1)))\n    pipeline = Pipeline(estimators)\n    kfold = KFold(n_splits=5)\n    results = cross_val_score(pipeline, X, y, cv=kfold, scoring=scoring)\n    print(\"%d: %.5f (%.5f) MSE\" % (i, results.mean(), results.std()))\n    print((\"%d:\" % i), results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"evaluator(wider_model, 20, X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator(model_40, 40, X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator(model_60, 60, X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator(model_80, 80, X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to threshold\nimport math\nTHRESHOLD = 1 - math.log(500) / math.log(50000)\n\ndef binarize_immuno(score):\n    if score >= THRESHOLD: return 1\n    else: return 0\n\ndf_train_binding_bin = df_train_binding.copy()\ndf_train_binding_bin['Y_val'] = df_train_binding_bin['Y_val'].apply(lambda x: binarize_immuno(x))\n\ndf_train_binding_bin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nimport keras\n\nX_bin, y_bin = process_input_df(df_train_binding_bin)\n\ndef new_evaluator(mod, i, X, y, y_binary, out_file):\n\n    scoring='neg_mean_squared_error'\n    print(\"Got model\")\n    f = open(out_file, \"w\")\n\n    splits = 5\n    \n    for i in range(splits):\n        keras.backend.clear_session()\n    \n        model = mod(i)\n        model.fit(X, y, batch_size=32, epochs=5)\n        y_predict = model.predict(X)\n        \n        score = roc_auc_score(y_binary, y_predict)\n        print(\"AUC:\", score)\n        f.write(\"AUC on fold %d : %f\\n\" % (i+1, score))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_evaluator(wider_model, 20, X, y, y_bin, \"mlp_metrics.txt\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator(wider_classif_model, 20, X, y, scoring='roc_auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator(wider_classif_model, 40, X, y, scoring='roc_auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator(wider_classif_model, 60, X, y, scoring='roc_auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator(wider_classif_model, 80, X, y, scoring='roc_auc')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Debugging Work**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_binding=pd.read_csv(\"../input/binding-train-pseudo/binding_train_pseudo.csv\",index_col=0)\ndf_train_binding = df_train_binding[df_train_binding['Pep_Length'] <= 9]\ndf_train_binding_bin.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}